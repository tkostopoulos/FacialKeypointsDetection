{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     28\n",
      "False     3\n",
      "dtype: int64 \n",
      "\n",
      "Handling After: \n",
      "False    31\n",
      "dtype: int64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0720 19:45:07.642556  4100 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0720 19:45:07.654496  4100 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0720 19:45:07.656491  4100 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0720 19:45:07.673475  4100 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0720 19:45:07.775204  4100 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0720 19:45:07.780187  4100 deprecation.py:506] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0720 19:45:07.781156  4100 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Finished: 0:00:16.603499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0720 19:45:07.850970  4100 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0720 19:45:08.114285  4100 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "FC_Layers_Model (Sequential) (None, 30)                12650730  \n",
      "=================================================================\n",
      "Total params: 27,365,418\n",
      "Trainable params: 12,650,730\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "\n",
      " Check for correct Image Shape: (7049, 224, 224, 3)\n",
      "\n",
      " Check Image Orientation: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Does the computer recognize a GPU: 1\n",
      "\n",
      "Modified Vgg16 Generated: 0:00:02.347874\n"
     ]
    }
   ],
   "source": [
    "# Data used can be found at:\n",
    "# https://www.kaggle.com/c/facial-keypoints-detection/data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import keras as K # importing this just in case\n",
    "\n",
    "from keras import backend\n",
    "\n",
    "# Warning with Jupyter notebook use, \n",
    "# if something is wrong in these files you have to leave the notebook, \n",
    "# shutdown and reopen to implement\n",
    "from VGG16 import VGG16_Obj # contains the keras models I made\n",
    "from TrainImageObj import TrainImage # contains some viewing and V&V data \n",
    "\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "####################################### definitions for data import#######################################\n",
    "cwd = os.getcwd()\n",
    "test = False # just incase there is something we need to test in this\n",
    "start = datetime.now()\n",
    "masterStart = datetime.now()\n",
    "\n",
    "projectDirectory = \"C:\\\\Users\\\\Ted\\\\Projects\\\\Python\\\\FacialKeypointsDetection\"\n",
    "dataDir = \"E:\\\\TK_PracticeDatabases\\\\facial-keypoints-detection\"\n",
    "os.chdir(dataDir)\n",
    "testData = pd.read_csv(\"test.csv\")\n",
    "trainingData = pd.read_csv(\"training.csv\")\n",
    "idLookupData = pd.read_csv(\"IdLookupTable.csv\")\n",
    "sampleSubData = pd.read_csv(\"SampleSubmission.csv\")\n",
    "\n",
    "\n",
    "# borrowed these line from Karan Jakhar's post\n",
    "b4NanFill = trainingData.isnull().any().value_counts() # only present for the print statement\n",
    "trainingData.fillna(0, inplace=True) # replace nans with '0' \n",
    "afterNanFill = trainingData.isnull().any().value_counts() # only present for the print statement\n",
    "#\"Big thank you to Karan Jakhar's post for these lines \\n\\nB4Nan Handling :  \\n\"\n",
    "print(str(b4NanFill) + \" \\n\\nHandling After: \\n\" + str(afterNanFill) +\"\\n\")\n",
    "del b4NanFill\n",
    "del afterNanFill # don't need to delete these to free up memory but doesn't hurt\n",
    "\n",
    "\n",
    "#########################################################\n",
    "# Need to test TK 7/17/2019\n",
    "dataInput = TrainImage(trainingData, 0) # 0 does not matter, the obj gives us all images as well\n",
    "trainingImageMatrix = dataInput.trainingImageMatrix\n",
    "validationData = dataInput.validationData\n",
    "#########################################################\n",
    "\n",
    "os.chdir(cwd)\n",
    "\n",
    "if test: # in the begining take a look at the training data\n",
    "    print(trainingData)\n",
    "\n",
    "importComplete = datetime.now()\n",
    "print(\"Import Finished: \" + str(importComplete - start))\n",
    "\n",
    "\n",
    "########################################## Generate the model ##########################################\n",
    "start = datetime.now()\n",
    "\n",
    "os.chdir(projectDirectory)\n",
    "vgg16 = VGG16_Obj()\n",
    "\n",
    "model = vgg16.modelReducedFC # this is where I import the Transfer Learning Model\n",
    "# make sure you take a look at the VGG16.py script, this is where the Keras Model takes place\n",
    "\n",
    "model.summary() # this will give us the VGG16 without the fully connected layers and label the new FCs as sequentional_1\n",
    "# we are using the VGG16 as a feature extractor and not changing them!!!\n",
    "\n",
    "print(\"\\n Check for correct Image Shape: \" + str(trainingImageMatrix.shape))\n",
    "print(\"\\n Check Image Orientation: \")\n",
    "image = trainingImageMatrix[0]\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "del image # save the memory\n",
    "\n",
    "\n",
    "# check if tensorflow sees my GPU\n",
    "print(\"\\nDoes the computer recognize a GPU: \" + str(len(backend.tensorflow_backend._get_available_gpus())))\n",
    "\n",
    "importComplete = datetime.now()\n",
    "print(\"\\nModified Vgg16 Generated: \" + str(importComplete - start))\n",
    "plt.close() # close the figure for non-jupyter notebook applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0720 19:45:09.996414  4100 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5639 samples, validate on 1410 samples\n",
      "Epoch 1/10\n",
      "5639/5639 [==============================] - 52s 9ms/step - loss: 352.6616 - mean_absolute_error: 13.6399 - acc: 0.5540 - val_loss: 100.7346 - val_mean_absolute_error: 6.1773 - val_acc: 0.9936\n",
      "Epoch 2/10\n",
      "5639/5639 [==============================] - 49s 9ms/step - loss: 171.4919 - mean_absolute_error: 9.2413 - acc: 0.6538 - val_loss: 104.8087 - val_mean_absolute_error: 6.0953 - val_acc: 0.9929\n",
      "Epoch 3/10\n",
      "5639/5639 [==============================] - 50s 9ms/step - loss: 127.8685 - mean_absolute_error: 7.7320 - acc: 0.7122 - val_loss: 115.3878 - val_mean_absolute_error: 6.2036 - val_acc: 0.9894\n",
      "Epoch 4/10\n",
      "5639/5639 [==============================] - 50s 9ms/step - loss: 110.2004 - mean_absolute_error: 7.0627 - acc: 0.7459 - val_loss: 159.1378 - val_mean_absolute_error: 7.3862 - val_acc: 0.9695\n",
      "Epoch 5/10\n",
      "5639/5639 [==============================] - 50s 9ms/step - loss: 91.1591 - mean_absolute_error: 6.3090 - acc: 0.7601 - val_loss: 110.3194 - val_mean_absolute_error: 5.9274 - val_acc: 0.9879\n",
      "Epoch 6/10\n",
      "5639/5639 [==============================] - 49s 9ms/step - loss: 82.4640 - mean_absolute_error: 5.9639 - acc: 0.7796 - val_loss: 91.7309 - val_mean_absolute_error: 4.9949 - val_acc: 0.9879\n",
      "Epoch 7/10\n",
      "5639/5639 [==============================] - 49s 9ms/step - loss: 77.2479 - mean_absolute_error: 5.7297 - acc: 0.7907 - val_loss: 118.8090 - val_mean_absolute_error: 5.8973 - val_acc: 0.9837\n",
      "Epoch 8/10\n",
      "5639/5639 [==============================] - 49s 9ms/step - loss: 67.0541 - mean_absolute_error: 5.2666 - acc: 0.7950 - val_loss: 95.2712 - val_mean_absolute_error: 5.2268 - val_acc: 0.9929\n",
      "Epoch 9/10\n",
      "5639/5639 [==============================] - 50s 9ms/step - loss: 62.9218 - mean_absolute_error: 5.1257 - acc: 0.7998 - val_loss: 99.8032 - val_mean_absolute_error: 5.3910 - val_acc: 0.9950\n",
      "Epoch 10/10\n",
      "5639/5639 [==============================] - 50s 9ms/step - loss: 63.5761 - mean_absolute_error: 5.0559 - acc: 0.7952 - val_loss: 115.4309 - val_mean_absolute_error: 5.8738 - val_acc: 0.9879\n",
      "\n",
      "Fitting Complete: 0:08:17.670907\n"
     ]
    }
   ],
   "source": [
    "########################################## fit to model ##########################################\n",
    "start = datetime.now()\n",
    "##log all the loss data\n",
    "#csvLogging = K.callbacks.CSVLogger(\"FacialPointExtractor_Loss.log\", append=True)\n",
    "\n",
    "model.compile(optimizer = 'adam', # adam seems to be the best optimizer I've used (mostly for classification tho) \n",
    "              loss = 'mse', # mse because we want a continuous number!!!\n",
    "              metrics = ['mae', 'accuracy']) # print/log some extra info\n",
    "#'''\n",
    "model.fit(trainingImageMatrix, validationData,  #need data to insert \n",
    "          batch_size=32, # make this a power of 2 for best performance\n",
    "          epochs=10, # more epochs better the prediction until gain is saturated, start small and go bigger if needed\n",
    "          shuffle=True, # shuffling is never a bad idea...\n",
    "          verbose=True, # show me progress per epoch\n",
    "          #callbacks=[csv_logger] # log the data?\n",
    "          validation_split=0.2) # take a 1/5 of the data for validation purposes '''\n",
    "\n",
    "\n",
    "doneFitting = datetime.now()\n",
    "print(\"\\nFitting Complete: \" + str(doneFitting-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(projectDirectory)\n",
    "model_json = model.to_json()\n",
    "with open(\"FacialKey_FC_500_200.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Working Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# check if tensorflow is using the GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = trainingImageMatrix[0]\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    # Oiginal binary crossentropy (see losses.py):\n",
    "    # K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "    # Calculate the binary crossentropy\n",
    "    \n",
    "    one_weight = 0.75\n",
    "    zero_weight = 1.0 - one_weight\n",
    "    b_ce = K.binary_crossentropy(y_true, y_pred)\n",
    "    # Apply the weights\n",
    "    weight_vector = y_true * one_weight + (1. - y_true) * zero_weight\n",
    "    weighted_b_ce = weight_vector * b_ce\n",
    "    # Return the mean error\n",
    "    return K.mean(weighted_b_ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Defining Arcitecture for Neural Net\n",
    "## OBJ\n",
    "- __init__\n",
    "    - defines functions that can be called only \n",
    "- First Function\n",
    "    - VGG16 sequentially network\n",
    "    - boolean on training CNN layers\n",
    "    - boolean for using the CNN layers as feature extractor\n",
    "    - boolean on training Neural Net layers\n",
    "    - weight to the 1s \n",
    "        - if =np.nan then weights are .5 and .5 for weighted X-entropy\n",
    "    - Output: full architecture\n",
    "- Second Function\n",
    "    - Training Layer\n",
    "    - Output: Fully Trained Model\n",
    "- Third Function\n",
    "    - Testing Layer\n",
    "    - Output: Model to be used on Data\n",
    "    \n",
    "# Defining Arcitecture for Neural Net\n",
    "## OBJ\n",
    "- __init__\n",
    "    - defines functions that can be called only \n",
    "- First Function\n",
    "    - K fold cross validation\n",
    "    - input 2 ints \n",
    "        - number of 0s\n",
    "        - number of 1s\n",
    "            - if only the first one populated then force weighted k fold to be false\n",
    "    - number of bins\n",
    "        - if bins = np.nan, then calculate even number of bins, if %bins  less than bins then add to final  \n",
    "    - boolean for weighted k fold (evenly distributed) making even 1s in each bin\n",
    "        - just incase unweighted 0s and 1s\n",
    "        - separate the input vector into 2\n",
    "    - Output: bins that are itterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eye_center_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eye_center_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eye_inner_corner_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eye_inner_corner_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eye_outer_corner_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eye_outer_corner_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eyebrow_inner_end_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eyebrow_inner_end_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eyebrow_outer_end_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eyebrow_outer_end_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eye_center_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eye_center_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eye_inner_corner_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eye_inner_corner_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eye_outer_corner_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eye_outer_corner_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eyebrow_inner_end_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eyebrow_inner_end_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eyebrow_outer_end_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eyebrow_outer_end_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"nose_tip_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"nose_tip_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_left_corner_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_left_corner_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_right_corner_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_right_corner_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_center_top_lip_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_center_top_lip_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_center_bottom_lip_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_center_bottom_lip_x\"][index] = 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-17d7e3330d26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageDir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m209\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# starting where the Nans are\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpatient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# load the images, labeled and not labeled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, trainData, index)\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eye_outer_corner_x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eyebrow_inner_end_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eyebrow_inner_end_x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eyebrow_inner_end_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eyebrow_inner_end_x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eyebrow_outer_end_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eyebrow_outer_end_x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m         \u001b[1;31m# do the setitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1038\u001b[1;33m         \u001b[0mcacher_needs_updating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_chained_assignment_possible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1039\u001b[0m         \u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_check_is_chained_assignment_possible\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3197\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mref\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m                 self._check_setitem_copy(stacklevel=4, t='referant',\n\u001b[1;32m-> 3199\u001b[1;33m                                          force=True)\n\u001b[0m\u001b[0;32m   3200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3201\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[1;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[0;32m   3244\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3245\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3246\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_referents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3247\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3248\u001b[0m                     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# save all images that are not labeled and labeled until a nan appears \n",
    "# for the first time \n",
    "\n",
    "imageDir = \"SubplotImages\"\n",
    "os.chdir(imageDir)\n",
    "for i in range(0,209):#,len(trainingData)): # only need so many (Nans make anything beyond this tricky to say the least)\n",
    "    patient = TrainImage(trainingData, i) # load the images, labeled and not labeled\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(patient.image)\n",
    "    plt.title(str(i)+\" Base\")\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(patient.labeledImage)\n",
    "    plt.title(str(i)+\" Labeled\")\n",
    "    plt.savefig(str(i)+\" Base&Labeled\")\n",
    "    plt.close()\n",
    "os.chdir(cwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
