{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Finished: 0:00:04.584662\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/c/facial-keypoints-detection/data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import keras as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "from TrainImageObj import TrainImage # be careful with the tab vs ' '\n",
    "# object used to debug and evaluate imported images\n",
    "#CAREFUL: I did not handle nans, and in the presence of a nan an error occurs \n",
    "\n",
    "cwd = os.getcwd()\n",
    "test = False\n",
    "start = datetime.now()\n",
    "\n",
    "projectDirectory = \"C:\\\\Users\\\\Ted\\\\Projects\\\\Python\\\\FacialKeypointsDetection\"\n",
    "dataDir = \"E:\\\\TK_PracticeDatabases\\\\facial-keypoints-detection\"\n",
    "os.chdir(dataDir)\n",
    "testData = pd.read_csv(\"test.csv\")\n",
    "trainingData = pd.read_csv(\"training.csv\")\n",
    "idLookupData = pd.read_csv(\"IdLookupTable.csv\")\n",
    "sampleSubData = pd.read_csv(\"SampleSubmission.csv\")\n",
    "\n",
    "os.chdir(cwd)\n",
    "\n",
    "if test:\n",
    "    print(trainingData)\n",
    "\n",
    "importComplete = datetime.now()\n",
    "print(\"Import Finished: \" + str(importComplete - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"block1_conv1\", padding=\"same\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"block5_conv2\", padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "os.chdir(projectDirectory)\n",
    "vgg16 = VGG16(FC_Include=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16(ClassicVGG16=True, \n",
    "          FC_Include = True,\n",
    "          classificationNumber = 1000,\n",
    "          l2_weight = 5e-04,\n",
    "          like_its_hot = 0.7, # drop regulation\n",
    "          FeatureExtractorTraining = False, \n",
    "          FCTraining = True,\n",
    "          weights= 'imagenet', \n",
    "          input_tensor=None): \n",
    "    ''' \n",
    "    # Inputs\n",
    "    FC_Include = using the network as a feature extractor based on the convolutional layers\n",
    "    FullyConnected = if training is needed for the fully connected layer\n",
    "    classificationNumber = number of components \n",
    "    FeatureExtractorTraining = if you need to train the middle layers\n",
    "    weights = 'imagenet' means using the weights from a network pretrained by imagenet challenge\n",
    "    \n",
    "    Rules:\n",
    "    - CANNOT have MORE than 1000 outputs (can't really see a case where they're would be >1k but eat your heart out.\n",
    "    - Use the excess and keep training on the FC layers true\n",
    "    - Need to append additional layers of lower training weights if want to use the non-FC layers\n",
    "    \n",
    "    # Returns\n",
    "        VGG16 Network\n",
    "    '''\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "    # Determine proper input shape\n",
    "    if ClassicVGG16:\n",
    "        inputShape = (224, 224, 3)\n",
    "    else:\n",
    "        inputShape = (None, None, 3)\n",
    "    \n",
    "    img_input = K.Input(inputShape)\n",
    "    \n",
    "    # Block 1     \n",
    "    b1_1 = K.layers.Conv2D(64, (3, 3), \n",
    "                  activation='relu', \n",
    "                  border_mode='same', \n",
    "                  name='block1_conv1')\n",
    "    b1_1.trainable = FeatureExtractorTraining\n",
    "    x = b1_1(img_input)\n",
    "    \n",
    "    b1_2 = K.layers.Conv2D(64, (3, 3), \n",
    "                  activation='relu', \n",
    "                  padding='same', \n",
    "                  name='block1_conv2')\n",
    "    b1_2.trainable = FeatureExtractorTraining\n",
    "    x = b1_2(x)#_normalized)\n",
    "    \n",
    "    x = K.layers.MaxPooling2D((2,2), strides=(2,2), name='block1_pool')(x) \n",
    "    \n",
    "    # Block 2\n",
    "    b2_1 = K.layers.Conv2D(128, \n",
    "                  (3, 3), \n",
    "                  activation='relu', \n",
    "                  padding='same', \n",
    "                  name='block2_conv1')\n",
    "    b2_1.trainable = FeatureExtractorTraining\n",
    "    x = b2_1(x)\n",
    "    \n",
    "    b2_2 = K.layers.Conv2D(128, (3, 3), \n",
    "                  activation='relu', \n",
    "                  padding='same', \n",
    "                  name='block2_conv2')\n",
    "    b2_2.trainable = FeatureExtractorTraining\n",
    "    x = b2_2(x)#_normalized)\n",
    "    \n",
    "    x = K.layers.MaxPooling2D((2,2), strides=(2,2) , name='block2_pool')(x)#_normalized) # decrease the amout of data points with no rounding loss\n",
    "    \n",
    "    # Block 3\n",
    "    # convolution block\n",
    "    \n",
    "    b3_1 = K.layers.Conv2D(256, (3, 3), \n",
    "                  activation='relu', \n",
    "                  padding='same', \n",
    "                  name='block3_conv1')\n",
    "    b3_1.trainable = FeatureExtractorTraining\n",
    "    x = b3_1(x)\n",
    "    \n",
    "    b3_2 = K.layers.Conv2D(256, (3, 3), \n",
    "                  activation='relu', \n",
    "                  padding='same', \n",
    "                  name='block3_conv2')\n",
    "    b3_2.trainable = FeatureExtractorTraining\n",
    "    x = b3_2(x)#_normalized)\n",
    "\n",
    "    b3_3 = K.layers.Conv2D(256, (3, 3), \n",
    "                  activation='relu', \n",
    "                  padding='same', \n",
    "                  name='block3_conv3')\n",
    "    b3_3.trainable = FeatureExtractorTraining\n",
    "    x = b3_3(x)#_normalized)\n",
    "    \n",
    "    x = K.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    \n",
    "    # Block 4 identity doc\n",
    "    \n",
    "    b4_1 = K.layers.Conv2D(512, (3, 3), \n",
    "                  activation='relu', \n",
    "                  padding='same', \n",
    "                  name='block4_conv1')\n",
    "    b4_1.trainable = FeatureExtractorTraining\n",
    "    x = b4_1(x)\n",
    "    \n",
    "    b4_2 = K.layers.Conv2D(512, (3, 3), \n",
    "                  activation='relu', \n",
    "                  padding='same', \n",
    "                  name='block4_conv2')\n",
    "    b4_2.trainable = FeatureExtractorTraining\n",
    "    x = b4_2(x)#_normalized)\n",
    "\n",
    "    b4_3 = K.layers.Conv2D(512, (3, 3), \n",
    "                  activation='relu', \n",
    "                  padding='same', \n",
    "                  name='block4_conv3')\n",
    "    b4_3.trainable = FeatureExtractorTraining\n",
    "    x = b4_3(x)#_normalized)\n",
    "    \n",
    "    x = K.layers.MaxPooling2D((2,2), strides=(2,2), name='block4_pool')(x)\n",
    "    \n",
    "    #Block 5\n",
    "    b5_1 = K.layers.Conv2D(512, (3, 3), \n",
    "                  activation='relu', \n",
    "                  padding='same', \n",
    "                  name='block5_conv1')\n",
    "    b5_1.trainable = FeatureExtractorTraining\n",
    "    x = b5_1(x)\n",
    "    \n",
    "    b5_2 = K.layers.Conv2D(512, (3, 3), \n",
    "                  activation='relu', \n",
    "                  border_mode='same', \n",
    "                  name='block5_conv2')\n",
    "    b5_2.trainable = FeatureExtractorTraining\n",
    "    x = b5_2(x)\n",
    "    \n",
    "    b5_3 = K.layers.Conv2D(512, (3, 3), \n",
    "                  activation='relu', \n",
    "                  padding='same', \n",
    "                  name='block5_conv3')\n",
    "    b5_3.trainable = FeatureExtractorTraining\n",
    "    x = b5_3(x)\n",
    "    \n",
    "    x = K.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if FC_Include:\n",
    "        # Classification block\n",
    "        x = K.layers.Flatten(name='flatten')(x)\n",
    "        \n",
    "        #x = Dropout(like_its_hot, name = 'regulator_0')(x)\n",
    "        fc1 = K.layers.Dense(4096, activation='relu',\n",
    "                    kernel_regularizer=K.regularizers.l2(l2_weight),\n",
    "                    name='fc1')\n",
    "        fc1.trainable = FCTraining\n",
    "        x = fc1(x)\n",
    "        \n",
    "        x = K.layers.Dropout(like_its_hot, name = 'regulator_1')(x)\n",
    "        \n",
    "        fc2 = K.layers.Dense(4096, \n",
    "                    activation='relu', \n",
    "                    kernel_regularizer=K.regularizers.l2(l2_weight),\n",
    "                    name='fc2')\n",
    "        fc2.trainable = FCTraining\n",
    "        x = fc2(x)\n",
    "        \n",
    "        x = K.layers.Dropout(like_its_hot, name = 'regulator_2')(x)\n",
    "        \n",
    "        pred  = K.layers.Dense(classificationNumber, \n",
    "                      activation='softmax', \n",
    "                      kernel_regularizer=K.regularizers.l2(l2_weight),\n",
    "                      name='pred')(x)\n",
    "        \n",
    "        model = K.Model(img_input, pred)\n",
    "        \n",
    "    else: ########################################################################################\n",
    "        print (\"You got no legs Lieutenant Dan!!!\")\n",
    "        model = K.Model(img_input,x)\n",
    "        \n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        currentCwd = os.getcwd()\n",
    "        os.chdir(projectDirectory) # hard coded for my directory\n",
    "        if FC_Include == False:\n",
    "            modelWeights = model.load_weights('vgg16Weights_noFC.h5')            \n",
    "        elif FC_Include == True: # only include the top if has \n",
    "            modelWeights = model.load_weights('vgg16Weights_FCincluded.h5')\n",
    "        os.chdir(currentCwd)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    # Oiginal binary crossentropy (see losses.py):\n",
    "    # K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "    # Calculate the binary crossentropy\n",
    "    \n",
    "    one_weight = 0.75\n",
    "    zero_weight = 1.0 - one_weight\n",
    "    b_ce = K.binary_crossentropy(y_true, y_pred)\n",
    "    # Apply the weights\n",
    "    weight_vector = y_true * one_weight + (1. - y_true) * zero_weight\n",
    "    weighted_b_ce = weight_vector * b_ce\n",
    "    # Return the mean error\n",
    "    return K.mean(weighted_b_ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Defining Arcitecture for Neural Net\n",
    "## OBJ\n",
    "- __init__\n",
    "    - defines functions that can be called only \n",
    "- First Function\n",
    "    - VGG16 sequentially network\n",
    "    - boolean on training CNN layers\n",
    "    - boolean for using the CNN layers as feature extractor\n",
    "    - boolean on training Neural Net layers\n",
    "    - weight to the 1s \n",
    "        - if =np.nan then weights are .5 and .5 for weighted X-entropy\n",
    "    - Output: full architecture\n",
    "- Second Function\n",
    "    - Training Layer\n",
    "    - Output: Fully Trained Model\n",
    "- Third Function\n",
    "    - Testing Layer\n",
    "    - Output: Model to be used on Data\n",
    "    \n",
    "# Defining Arcitecture for Neural Net\n",
    "## OBJ\n",
    "- __init__\n",
    "    - defines functions that can be called only \n",
    "- First Function\n",
    "    - K fold cross validation\n",
    "    - input 2 ints \n",
    "        - number of 0s\n",
    "        - number of 1s\n",
    "            - if only the first one populated then force weighted k fold to be false\n",
    "    - number of bins\n",
    "        - if bins = np.nan, then calculate even number of bins, if %bins  less than bins then add to final  \n",
    "    - boolean for weighted k fold (evenly distributed) making even 1s in each bin\n",
    "        - just incase unweighted 0s and 1s\n",
    "        - separate the input vector into 2\n",
    "    - Output: bins that are itterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eye_center_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eye_center_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eye_inner_corner_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eye_inner_corner_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eye_outer_corner_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eye_outer_corner_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eyebrow_inner_end_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eyebrow_inner_end_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eyebrow_outer_end_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"left_eyebrow_outer_end_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eye_center_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eye_center_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eye_inner_corner_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eye_inner_corner_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eye_outer_corner_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eye_outer_corner_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eyebrow_inner_end_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eyebrow_inner_end_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eyebrow_outer_end_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"right_eyebrow_outer_end_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"nose_tip_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"nose_tip_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_left_corner_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_left_corner_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_right_corner_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_right_corner_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_center_top_lip_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_center_top_lip_x\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_center_bottom_lip_y\"][index] = 0\n",
      "C:\\Users\\Ted\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  trainData[\"mouth_center_bottom_lip_x\"][index] = 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-17d7e3330d26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageDir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m209\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# starting where the Nans are\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpatient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# load the images, labeled and not labeled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Projects\\Python\\FacialKeypointsDetection\\TrainImageObj.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, trainData, index)\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eye_outer_corner_x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eyebrow_inner_end_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eyebrow_inner_end_x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eyebrow_inner_end_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eyebrow_inner_end_x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eyebrow_outer_end_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"left_eyebrow_outer_end_x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m         \u001b[1;31m# do the setitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1038\u001b[1;33m         \u001b[0mcacher_needs_updating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_chained_assignment_possible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1039\u001b[0m         \u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_check_is_chained_assignment_possible\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3197\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mref\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m                 self._check_setitem_copy(stacklevel=4, t='referant',\n\u001b[1;32m-> 3199\u001b[1;33m                                          force=True)\n\u001b[0m\u001b[0;32m   3200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3201\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[1;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[0;32m   3244\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3245\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3246\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_referents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3247\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3248\u001b[0m                     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# save all images that are not labeled and labeled until a nan appears \n",
    "# for the first time \n",
    "\n",
    "imageDir = \"SubplotImages\"\n",
    "os.chdir(imageDir)\n",
    "for i in range(0,209):#,len(trainingData)): # only need so many (Nans make anything beyond this tricky to say the least)\n",
    "    patient = TrainImage(trainingData, i) # load the images, labeled and not labeled\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(patient.image)\n",
    "    plt.title(str(i)+\" Base\")\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(patient.labeledImage)\n",
    "    plt.title(str(i)+\" Labeled\")\n",
    "    plt.savefig(str(i)+\" Base&Labeled\")\n",
    "    plt.close()\n",
    "os.chdir(cwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
